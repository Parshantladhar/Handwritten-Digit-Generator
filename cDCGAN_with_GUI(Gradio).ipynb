{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNgtgj4V+upfw3dxAqpmFxt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Parshantladhar/Handwritten-Digit-Generator/blob/main/cDCGAN_with_GUI(Gradio).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import PIL\n",
        "import imageio\n",
        "from IPython import display"
      ],
      "metadata": {
        "id": "aWONECT9HuUy"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE_G = 2e-4\n",
        "LEARNING_RATE_D = 5e-4\n",
        "EPOCHS = 100\n",
        "noise_dim = 100\n",
        "num_classes = 10  # For digits 0-9"
      ],
      "metadata": {
        "id": "TiYwKo47HwKQ"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set mixed precision for better performance\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy('mixed_float16')"
      ],
      "metadata": {
        "id": "8B-17ZsSHxzg"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_mnist():\n",
        "    # Load and prepare the MNIST dataset\n",
        "    (train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "    # Reshape and normalize images\n",
        "    train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "    train_images = (train_images - 127.5) / 127.5\n",
        "\n",
        "    # Convert labels to one-hot encoding\n",
        "    train_labels = tf.one_hot(train_labels, depth=num_classes)\n",
        "\n",
        "    # Create tf.data.Dataset\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "    train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    return train_dataset"
      ],
      "metadata": {
        "id": "sXCJXda_H0FY"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a simpler approach instead of custom SpectralNormalization\n",
        "def make_generator_model():\n",
        "    # Input for noise vector\n",
        "    noise_input = layers.Input(shape=(noise_dim,))\n",
        "\n",
        "    # Input for digit class (one-hot encoded)\n",
        "    digit_input = layers.Input(shape=(num_classes,))\n",
        "\n",
        "    # Embedding for digit conditioning (linear projection)\n",
        "    digit_embedding = layers.Dense(noise_dim)(digit_input)\n",
        "\n",
        "    # Combine noise and digit embedding (element-wise multiplication)\n",
        "    combined_input = layers.Multiply()([noise_input, digit_embedding])\n",
        "\n",
        "    # Dense layer and reshape\n",
        "    x = layers.Dense(7*7*256, use_bias=False)(combined_input)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    x = layers.Reshape((7, 7, 256))(x)\n",
        "\n",
        "    # Upsampling blocks\n",
        "    x = layers.UpSampling2D(size=(2, 2))(x)\n",
        "    x = layers.Conv2D(128, (3, 3), padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    x = layers.UpSampling2D(size=(2, 2))(x)\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    # Output layer with tanh activation\n",
        "    output = layers.Conv2D(1, (3, 3), padding='same', use_bias=False, activation='tanh')(x)\n",
        "\n",
        "    # Create model with two inputs\n",
        "    model = tf.keras.Model(inputs=[noise_input, digit_input], outputs=output)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "9hWciem7H3mo"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_discriminator_model():\n",
        "    # Input for images\n",
        "    image_input = layers.Input(shape=[28, 28, 1])\n",
        "\n",
        "    # Input for digit class (one-hot encoded)\n",
        "    digit_input = layers.Input(shape=(num_classes,))\n",
        "\n",
        "    # Process digit conditioning\n",
        "    digit_embedding = layers.Dense(28*28)(digit_input)\n",
        "    digit_embedding = layers.Reshape((28, 28, 1))(digit_embedding)\n",
        "\n",
        "    # Combine image and digit embedding\n",
        "    x = layers.Concatenate()([image_input, digit_embedding])\n",
        "\n",
        "    # Convolutional layers (using standard Conv2D now)\n",
        "    x = layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
        "                     kernel_initializer=tf.keras.initializers.Orthogonal(gain=0.8))(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    x = layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same',\n",
        "                     kernel_initializer=tf.keras.initializers.Orthogonal(gain=0.8))(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    # Dense layers\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(128, kernel_initializer=tf.keras.initializers.Orthogonal(gain=0.8))(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "    output = layers.Dense(1)(x)\n",
        "\n",
        "    # Create model with two inputs\n",
        "    model = tf.keras.Model(inputs=[image_input, digit_input], outputs=output)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "eDX4rZB9H8o5"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create generator and discriminator\n",
        "generator = make_generator_model()\n",
        "discriminator = make_discriminator_model()"
      ],
      "metadata": {
        "id": "N5jqqnbiH-7a"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss functions\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "QGzG0RC7IAUw"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output) * 0.9, real_output)  # Smoothed labels\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output) * 0.1, fake_output)  # Smoothed labels\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "tH6nOAiuIB2g"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "metadata": {
        "id": "rnTKVIrAIEFB"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizers\n",
        "generator_optimizer = tf.keras.optimizers.Adam(LEARNING_RATE_G, beta_1=0.5, beta_2=0.999)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(LEARNING_RATE_D, beta_1=0.5, beta_2=0.999)"
      ],
      "metadata": {
        "id": "b_kCgAbjIFeB"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checkpoint setup\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                discriminator_optimizer=discriminator_optimizer,\n",
        "                                generator=generator,\n",
        "                                discriminator=discriminator)"
      ],
      "metadata": {
        "id": "_iqb-VdlIHqL"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create seed for visualization\n",
        "num_examples_to_generate = 16\n",
        "seed_noise = tf.random.normal([num_examples_to_generate, noise_dim])\n",
        "seed_digits = tf.one_hot([i % 10 for i in range(num_examples_to_generate)], num_classes)"
      ],
      "metadata": {
        "id": "nTjP876pIKy5"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "    # Generate random noise and random digit labels\n",
        "    batch_size = tf.shape(images)[0]\n",
        "    noise = tf.random.normal([batch_size, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        # Generate fake images\n",
        "        generated_images = generator([noise, labels], training=True)\n",
        "\n",
        "        # Get discriminator decisions\n",
        "        real_output = discriminator([images, labels], training=True)\n",
        "        fake_output = discriminator([generated_images, labels], training=True)\n",
        "\n",
        "        # Calculate losses\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    # Calculate gradients\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    # Apply gradients\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    return gen_loss, disc_loss"
      ],
      "metadata": {
        "id": "MBXDTRVUIOT4"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_save_images(model, epoch, test_input_noise, test_input_digits):\n",
        "    # Ensure the prediction is in float32 for imshow\n",
        "    # Use .numpy() to convert the EagerTensor to a NumPy array before using .astype()\n",
        "    predictions = model([test_input_noise, test_input_digits], training=False).numpy().astype('float32')\n",
        "\n",
        "    fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        # Squeeze the channel dimension to match the expected shape for imshow\n",
        "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "        plt.title(f\"Digit: {tf.argmax(test_input_digits[i]).numpy()}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "    plt.close(fig)\n",
        "\n",
        "    return fig"
      ],
      "metadata": {
        "id": "DpaqG66sIQgA"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training history\n",
        "history = {\"gen_loss\": [], \"disc_loss\": [], \"accuracy\": []}\n",
        "\n",
        "def train(dataset, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "        epoch_gen_loss = 0\n",
        "        epoch_disc_loss = 0\n",
        "        steps = 0\n",
        "\n",
        "        for image_batch, label_batch in dataset:\n",
        "            gen_loss, disc_loss = train_step(image_batch, label_batch)\n",
        "            epoch_gen_loss += gen_loss\n",
        "            epoch_disc_loss += disc_loss\n",
        "            steps += 1\n",
        "\n",
        "        # Calculate average losses\n",
        "        epoch_gen_loss /= steps\n",
        "        epoch_disc_loss /= steps\n",
        "\n",
        "        # Update history\n",
        "        history[\"gen_loss\"].append(epoch_gen_loss.numpy())\n",
        "        history[\"disc_loss\"].append(epoch_disc_loss.numpy())\n",
        "        history[\"accuracy\"].append(1 - (epoch_gen_loss.numpy() / (epoch_gen_loss.numpy() + epoch_disc_loss.numpy())))\n",
        "\n",
        "        # Generate and save images\n",
        "        display.clear_output(wait=True)\n",
        "        fig = generate_and_save_images(generator, epoch + 1, seed_noise, seed_digits)\n",
        "\n",
        "        # Save checkpoint\n",
        "        if (epoch + 1) % 15 == 0:\n",
        "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "        print(f\"Generator Loss: {epoch_gen_loss:.4f}, Discriminator Loss: {epoch_disc_loss:.4f}\")\n",
        "        print(f\"Time: {time.time()-start:.2f} sec\")\n",
        "\n",
        "    # Save final history\n",
        "    np.save(\"training_history.npy\", history)"
      ],
      "metadata": {
        "id": "29HxwMz0ITOw"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and train\n",
        "train_dataset = load_mnist()\n",
        "train(train_dataset, EPOCHS)  # Train for just 1 epoch to test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "D1heWXGJId5R",
        "outputId": "c8c364d8-86fd-4f3d-85f7-b47c4714ffc9"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100/100\n",
            "Generator Loss: 0.9428, Discriminator Loss: 1.3012\n",
            "Time: 10.69 sec\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save models\n",
        "generator.save(\"generator_model.keras\")\n",
        "discriminator.save(\"discriminator_model.keras\")\n",
        "print(\"Models saved successfully in Keras format!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1seS2Cc7IkXx",
        "outputId": "7d4d3533-b1a9-4bcf-efd3-a4ffacdd72db"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models saved successfully in Keras format!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio interface\n",
        "import gradio as gr\n",
        "\n",
        "# Load the model (uncomment when you have a trained model)\n",
        "# generator = tf.keras.models.load_model(\"generator_model.keras\", compile=False)\n",
        "\n",
        "device = \"/GPU:0\" if tf.config.list_physical_devices('GPU') else \"/CPU:0\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "def generate_digit(digit=None):\n",
        "    if digit is None:\n",
        "        digit = np.random.randint(0, 10)\n",
        "    digit = np.clip(int(digit), 0, 9)\n",
        "\n",
        "    # Create one-hot encoding\n",
        "    digit_one_hot = np.zeros((1, 10))\n",
        "    digit_one_hot[0, digit] = 1\n",
        "\n",
        "    # Generate random noise\n",
        "    random_noise = np.random.randn(1, noise_dim)\n",
        "\n",
        "    with tf.device(device):\n",
        "        # Generate image using both noise and digit class\n",
        "        generated_image = generator.predict([random_noise, digit_one_hot])\n",
        "\n",
        "    # Process image for display\n",
        "    generated_image = generated_image.reshape(28, 28)\n",
        "    generated_image = generated_image * 127.5 + 127.5  # Denormalize\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.imshow(generated_image, cmap=\"gray\")\n",
        "    ax.set_title(f\"Generated Digit: {digit}\")\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "    return fig\n",
        "\n",
        "def analyze_performance():\n",
        "    try:\n",
        "        history = np.load(\"training_history.npy\", allow_pickle=True).item()\n",
        "\n",
        "        if not history:\n",
        "            return \"No valid performance data found!\"\n",
        "\n",
        "        gen_loss = history.get(\"gen_loss\", [])\n",
        "        disc_loss = history.get(\"disc_loss\", [])\n",
        "        accuracy = history.get(\"accuracy\", [])\n",
        "        epochs = range(1, len(gen_loss) + 1)\n",
        "\n",
        "        fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "        # Plot losses\n",
        "        ax[0].plot(epochs, gen_loss, \"r-\", label=\"Generator Loss\")\n",
        "        ax[0].plot(epochs, disc_loss, \"b-\", label=\"Discriminator Loss\")\n",
        "        ax[0].set_title(\"Model Losses Over Epochs\")\n",
        "        ax[0].set_xlabel(\"Epochs\")\n",
        "        ax[0].set_ylabel(\"Loss\")\n",
        "        ax[0].legend()\n",
        "\n",
        "        # Plot accuracy\n",
        "        ax[1].plot(epochs, accuracy, \"g-\", label=\"Generator Accuracy\")\n",
        "        ax[1].set_title(\"Model Accuracy Over Epochs\")\n",
        "        ax[1].set_xlabel(\"Epochs\")\n",
        "        ax[1].set_ylabel(\"Accuracy\")\n",
        "        ax[1].legend()\n",
        "\n",
        "        return fig\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "# Create Gradio interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# ‚úçÔ∏è Handwritten Digit Generator\")\n",
        "    gr.Markdown(\"Generate a **random** or **specific** handwritten digit using Conditional GAN! üöÄ\")\n",
        "\n",
        "    with gr.Row():\n",
        "        btn_random = gr.Button(\"üé≤ Generate Random Digit\")\n",
        "        num_input = gr.Number(label=\"Enter Digit (0-9)\", value=0, minimum=0, maximum=9, step=1)\n",
        "        btn_specific = gr.Button(\"üéØ Generate Specific Digit\")\n",
        "\n",
        "    output_image = gr.Plot()\n",
        "\n",
        "    btn_random.click(generate_digit, inputs=None, outputs=output_image)\n",
        "    btn_specific.click(generate_digit, inputs=num_input, outputs=output_image)\n",
        "\n",
        "    gr.Markdown(\"## üìä Model Performance Analysis\")\n",
        "    btn_analysis = gr.Button(\"üìà Show Performance\")\n",
        "    output_analysis = gr.Plot()\n",
        "\n",
        "    btn_analysis.click(analyze_performance, inputs=None, outputs=output_analysis)\n",
        "\n",
        "# Launch the interface\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "5sgRD7i8GIdF",
        "outputId": "7c7507e5-9889-479f-a5e1-9cdd332f7771"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: /GPU:0\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://43be03abfa8cf84dee.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://43be03abfa8cf84dee.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}