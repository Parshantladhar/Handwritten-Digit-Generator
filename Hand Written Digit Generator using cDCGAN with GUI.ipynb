{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN5cRjPmmHNnQkL7dGf+4f9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Parshantladhar/Handwritten-Digit-Generator/blob/main/Hand%20Written%20Digit%20Generator%20using%20cDCGAN%20with%20GUI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import PIL\n",
        "import imageio\n",
        "from IPython import display"
      ],
      "metadata": {
        "id": "aWONECT9HuUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE_G = 2e-4\n",
        "LEARNING_RATE_D = 5e-4\n",
        "EPOCHS = 100\n",
        "noise_dim = 100\n",
        "num_classes = 10  # For digits 0-9"
      ],
      "metadata": {
        "id": "TiYwKo47HwKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set mixed precision for better performance\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy('mixed_float16')"
      ],
      "metadata": {
        "id": "8B-17ZsSHxzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_mnist():\n",
        "    # Load and prepare the MNIST dataset\n",
        "    (train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "    # Reshape and normalize images\n",
        "    train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "    train_images = (train_images - 127.5) / 127.5\n",
        "\n",
        "    # Convert labels to one-hot encoding\n",
        "    train_labels = tf.one_hot(train_labels, depth=num_classes)\n",
        "\n",
        "    # Create tf.data.Dataset\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "    train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    return train_dataset"
      ],
      "metadata": {
        "id": "sXCJXda_H0FY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_generator_model():\n",
        "    # Input for noise vector\n",
        "    noise_input = layers.Input(shape=(noise_dim,))\n",
        "\n",
        "    # Input for digit class (one-hot encoded)\n",
        "    digit_input = layers.Input(shape=(num_classes,))\n",
        "\n",
        "    # Embedding for digit conditioning (linear projection)\n",
        "    digit_embedding = layers.Dense(noise_dim)(digit_input)\n",
        "\n",
        "    # Combine noise and digit embedding (element-wise multiplication)\n",
        "    combined_input = layers.Multiply()([noise_input, digit_embedding])\n",
        "\n",
        "    # Dense layer and reshape\n",
        "    x = layers.Dense(7*7*256, use_bias=False)(combined_input)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    x = layers.Reshape((7, 7, 256))(x)\n",
        "\n",
        "    # Upsampling blocks\n",
        "    x = layers.UpSampling2D(size=(2, 2))(x)\n",
        "    x = layers.Conv2D(128, (3, 3), padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    x = layers.UpSampling2D(size=(2, 2))(x)\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    # Output layer with tanh activation\n",
        "    output = layers.Conv2D(1, (3, 3), padding='same', use_bias=False, activation='tanh')(x)\n",
        "\n",
        "    # Create model with two inputs\n",
        "    model = tf.keras.Model(inputs=[noise_input, digit_input], outputs=output)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "9hWciem7H3mo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_discriminator_model():\n",
        "    # Input for images\n",
        "    image_input = layers.Input(shape=[28, 28, 1])\n",
        "\n",
        "    # Input for digit class (one-hot encoded)\n",
        "    digit_input = layers.Input(shape=(num_classes,))\n",
        "\n",
        "    # Process digit conditioning\n",
        "    digit_embedding = layers.Dense(28*28)(digit_input)\n",
        "    digit_embedding = layers.Reshape((28, 28, 1))(digit_embedding)\n",
        "\n",
        "    # Combine image and digit embedding\n",
        "    x = layers.Concatenate()([image_input, digit_embedding])\n",
        "\n",
        "    # Convolutional layers (using standard Conv2D now)\n",
        "    x = layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
        "                     kernel_initializer=tf.keras.initializers.Orthogonal(gain=0.8))(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    x = layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same',\n",
        "                     kernel_initializer=tf.keras.initializers.Orthogonal(gain=0.8))(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    # Dense layers\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(128, kernel_initializer=tf.keras.initializers.Orthogonal(gain=0.8))(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "    output = layers.Dense(1)(x)\n",
        "\n",
        "    # Create model with two inputs\n",
        "    model = tf.keras.Model(inputs=[image_input, digit_input], outputs=output)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "eDX4rZB9H8o5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create generator and discriminator\n",
        "generator = make_generator_model()\n",
        "discriminator = make_discriminator_model()"
      ],
      "metadata": {
        "id": "N5jqqnbiH-7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss functions\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "QGzG0RC7IAUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output) * 0.9, real_output)  # Smoothed labels\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output) * 0.1, fake_output)  # Smoothed labels\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "tH6nOAiuIB2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "metadata": {
        "id": "rnTKVIrAIEFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizers\n",
        "generator_optimizer = tf.keras.optimizers.Adam(LEARNING_RATE_G, beta_1=0.5, beta_2=0.999)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(LEARNING_RATE_D, beta_1=0.5, beta_2=0.999)"
      ],
      "metadata": {
        "id": "b_kCgAbjIFeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checkpoint setup\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                discriminator_optimizer=discriminator_optimizer,\n",
        "                                generator=generator,\n",
        "                                discriminator=discriminator)"
      ],
      "metadata": {
        "id": "_iqb-VdlIHqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create seed for visualization\n",
        "num_examples_to_generate = 16\n",
        "seed_noise = tf.random.normal([num_examples_to_generate, noise_dim])\n",
        "seed_digits = tf.one_hot([i % 10 for i in range(num_examples_to_generate)], num_classes)"
      ],
      "metadata": {
        "id": "nTjP876pIKy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "    # Generate random noise and random digit labels\n",
        "    batch_size = tf.shape(images)[0]\n",
        "    noise = tf.random.normal([batch_size, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        # Generate fake images\n",
        "        generated_images = generator([noise, labels], training=True)\n",
        "\n",
        "        # Get discriminator decisions\n",
        "        real_output = discriminator([images, labels], training=True)\n",
        "        fake_output = discriminator([generated_images, labels], training=True)\n",
        "\n",
        "        # Calculate losses\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    # Calculate gradients\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    # Apply gradients\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    return gen_loss, disc_loss"
      ],
      "metadata": {
        "id": "MBXDTRVUIOT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_save_images(model, epoch, test_input_noise, test_input_digits):\n",
        "    # Ensure the prediction is in float32 for imshow\n",
        "    # Use .numpy() to convert the EagerTensor to a NumPy array before using .astype()\n",
        "    predictions = model([test_input_noise, test_input_digits], training=False).numpy().astype('float32')\n",
        "\n",
        "    fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        # Squeeze the channel dimension to match the expected shape for imshow\n",
        "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "        plt.title(f\"Digit: {tf.argmax(test_input_digits[i]).numpy()}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "    plt.close(fig)\n",
        "\n",
        "    return fig"
      ],
      "metadata": {
        "id": "DpaqG66sIQgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training history\n",
        "history = {\"gen_loss\": [], \"disc_loss\": [], \"accuracy\": []}\n",
        "\n",
        "def train(dataset, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "        epoch_gen_loss = 0\n",
        "        epoch_disc_loss = 0\n",
        "        steps = 0\n",
        "\n",
        "        for image_batch, label_batch in dataset:\n",
        "            gen_loss, disc_loss = train_step(image_batch, label_batch)\n",
        "            epoch_gen_loss += gen_loss\n",
        "            epoch_disc_loss += disc_loss\n",
        "            steps += 1\n",
        "\n",
        "        # Calculate average losses\n",
        "        epoch_gen_loss /= steps\n",
        "        epoch_disc_loss /= steps\n",
        "\n",
        "        # Update history\n",
        "        history[\"gen_loss\"].append(epoch_gen_loss.numpy())\n",
        "        history[\"disc_loss\"].append(epoch_disc_loss.numpy())\n",
        "        history[\"accuracy\"].append(1 - (epoch_gen_loss.numpy() / (epoch_gen_loss.numpy() + epoch_disc_loss.numpy())))\n",
        "\n",
        "        # Generate and save images\n",
        "        display.clear_output(wait=True)\n",
        "        fig = generate_and_save_images(generator, epoch + 1, seed_noise, seed_digits)\n",
        "\n",
        "        # Save checkpoint\n",
        "        if (epoch + 1) % 15 == 0:\n",
        "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "        print(f\"Generator Loss: {epoch_gen_loss:.4f}, Discriminator Loss: {epoch_disc_loss:.4f}\")\n",
        "        print(f\"Time: {time.time()-start:.2f} sec\")\n",
        "\n",
        "    # Save final history\n",
        "    np.save(\"training_history.npy\", history)"
      ],
      "metadata": {
        "id": "29HxwMz0ITOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and train\n",
        "train_dataset = load_mnist()\n",
        "train(train_dataset, EPOCHS)"
      ],
      "metadata": {
        "id": "D1heWXGJId5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save models\n",
        "generator.save(\"generator_model.keras\")\n",
        "discriminator.save(\"discriminator_model.keras\")\n",
        "print(\"Models saved successfully in Keras format!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1seS2Cc7IkXx",
        "outputId": "7d4d3533-b1a9-4bcf-efd3-a4ffacdd72db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models saved successfully in Keras format!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "Uz3UPk3R1nLW",
        "outputId": "04c72298-7ac6-42de-ce4c-32ec0864192e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.25.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.8.0 (from gradio)\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.1)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.25.1-py3-none-any.whl (46.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.25.1 gradio-client-1.8.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.5 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio interface\n",
        "import gradio as gr\n",
        "\n",
        "# Load the model\n",
        "generator = tf.keras.models.load_model(\"generator_model.keras\", compile=False)\n",
        "\n",
        "device = \"/GPU:0\" if tf.config.list_physical_devices('GPU') else \"/CPU:0\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "def generate_digit(digit=None):\n",
        "    if digit is None:\n",
        "        digit = np.random.randint(0, 10)\n",
        "    digit = np.clip(int(digit), 0, 9)\n",
        "\n",
        "    # Create one-hot encoding\n",
        "    digit_one_hot = np.zeros((1, 10))\n",
        "    digit_one_hot[0, digit] = 1\n",
        "\n",
        "    # Generate random noise\n",
        "    random_noise = np.random.randn(1, noise_dim)\n",
        "\n",
        "    with tf.device(device):\n",
        "        # Generate image using both noise and digit class\n",
        "        generated_image = generator.predict([random_noise, digit_one_hot])\n",
        "\n",
        "    # Process image for display\n",
        "    generated_image = generated_image.reshape(28, 28)\n",
        "    generated_image = generated_image * 127.5 + 127.5  # Denormalize\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.imshow(generated_image, cmap=\"gray\")\n",
        "    ax.set_title(f\"Generated Digit: {digit}\")\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "    return fig\n",
        "\n",
        "def analyze_performance():\n",
        "    try:\n",
        "        history = np.load(\"training_history.npy\", allow_pickle=True).item()\n",
        "\n",
        "        if not history:\n",
        "            return \"No valid performance data found!\"\n",
        "\n",
        "        gen_loss = history.get(\"gen_loss\", [])\n",
        "        disc_loss = history.get(\"disc_loss\", [])\n",
        "        accuracy = history.get(\"accuracy\", [])\n",
        "        epochs = range(1, len(gen_loss) + 1)\n",
        "\n",
        "        fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "        # Plot losses\n",
        "        ax[0].plot(epochs, gen_loss, \"r-\", label=\"Generator Loss\")\n",
        "        ax[0].plot(epochs, disc_loss, \"b-\", label=\"Discriminator Loss\")\n",
        "        ax[0].set_title(\"Model Losses Over Epochs\")\n",
        "        ax[0].set_xlabel(\"Epochs\")\n",
        "        ax[0].set_ylabel(\"Loss\")\n",
        "        ax[0].legend()\n",
        "\n",
        "        # Plot accuracy\n",
        "        ax[1].plot(epochs, accuracy, \"g-\", label=\"Generator Accuracy\")\n",
        "        ax[1].set_title(\"Model Accuracy Over Epochs\")\n",
        "        ax[1].set_xlabel(\"Epochs\")\n",
        "        ax[1].set_ylabel(\"Accuracy\")\n",
        "        ax[1].legend()\n",
        "\n",
        "        return fig\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "# Create Gradio interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# ✍️ Handwritten Digit Generator\")\n",
        "    gr.Markdown(\"Generate a **random** or **specific** handwritten digit using Conditional GAN! 🚀\")\n",
        "\n",
        "    with gr.Row():\n",
        "        btn_random = gr.Button(\"🎲 Generate Random Digit\")\n",
        "        num_input = gr.Number(label=\"Enter Digit (0-9)\", value=0, minimum=0, maximum=9, step=1)\n",
        "        btn_specific = gr.Button(\"🎯 Generate Specific Digit\")\n",
        "\n",
        "    output_image = gr.Plot()\n",
        "\n",
        "    btn_random.click(generate_digit, inputs=None, outputs=output_image)\n",
        "    btn_specific.click(generate_digit, inputs=num_input, outputs=output_image)\n",
        "\n",
        "    gr.Markdown(\"## 📊 Model Performance Analysis\")\n",
        "    btn_analysis = gr.Button(\"📈 Show Performance\")\n",
        "    output_analysis = gr.Plot()\n",
        "\n",
        "    btn_analysis.click(analyze_performance, inputs=None, outputs=output_analysis)\n",
        "\n",
        "# Launch the interface\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "5sgRD7i8GIdF",
        "outputId": "232c0855-b30e-4558-936d-361509a47735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: /GPU:0\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://3e655feb4e9a3e445d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://3e655feb4e9a3e445d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}